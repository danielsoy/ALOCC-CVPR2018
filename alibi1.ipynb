{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsoy/ALOCC-CVPR2018/blob/master/alibi1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fl-NAckBZCvb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, Dense, Layer, Reshape, InputLayer, Flatten, Input, MaxPooling2D\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SeldonIO/alibi-detect.git\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxQx9zNQZavW",
        "outputId": "a147c3fd-44ad-415e-9ff5-41abd0fc7d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'alibi-detect'...\n",
            "remote: Enumerating objects: 4042, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 4042 (delta 0), reused 0 (delta 0), pack-reused 4038\u001b[K\n",
            "Receiving objects: 100% (4042/4042), 26.10 MiB | 30.20 MiB/s, done.\n",
            "Resolving deltas: 100% (2584/2584), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/alibi-detect/alibi_detect/od"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Haxc9zqlaUlZ",
        "outputId": "7c17bb7b-190b-4e12-d9f5-d50dfa5e8348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/alibi-detect/alibi_detect/od\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install alibi-detect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SjGwpKBnaD6h",
        "outputId": "ff5b6334-9f23-484b-aaca-0936a91238af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting alibi-detect\n",
            "  Downloading alibi_detect-0.8.0-py3-none-any.whl (300 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 300 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from alibi-detect) (1.19.5)\n",
            "Requirement already satisfied: opencv-python<5.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from alibi-detect) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image!=0.17.1,<0.19,>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from alibi-detect) (0.18.3)\n",
            "Requirement already satisfied: dill<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from alibi-detect) (0.3.4)\n",
            "Requirement already satisfied: scikit-learn<1.1.0,>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from alibi-detect) (1.0.1)\n",
            "Requirement already satisfied: pandas<2.0.0,>=0.23.3 in /usr/local/lib/python3.7/dist-packages (from alibi-detect) (1.1.5)\n",
            "Collecting tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0\n",
            "  Downloading tensorflow-2.6.2-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 458.3 MB 11 kB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.0.0\n",
            "  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 44.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba!=0.54.0 in /usr/local/lib/python3.7/dist-packages (from alibi-detect) (0.51.2)\n",
            "Collecting tensorflow-probability<0.13.0,>=0.8.0\n",
            "  Downloading tensorflow_probability-0.12.2-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8 MB 21.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from alibi-detect) (3.2.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from alibi-detect) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in /usr/local/lib/python3.7/dist-packages (from alibi-detect) (4.62.3)\n",
            "Requirement already satisfied: Pillow<9.0.0,>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from alibi-detect) (7.1.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from alibi-detect) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba!=0.54.0->alibi-detect) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba!=0.54.0->alibi-detect) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=0.23.3->alibi-detect) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2.10)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.17.1,<0.19,>=0.14.2->alibi-detect) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.17.1,<0.19,>=0.14.2->alibi-detect) (1.2.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.17.1,<0.19,>=0.14.2->alibi-detect) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.17.1,<0.19,>=0.14.2->alibi-detect) (2021.11.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.20.2->alibi-detect) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.20.2->alibi-detect) (1.1.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (3.17.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (0.12.0)\n",
            "Collecting keras<2.7,>=2.6.0\n",
            "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (1.42.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (1.1.2)\n",
            "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
            "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 39.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (3.3.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (0.37.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (0.4.0)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tensorboard<2.7,>=2.6.0\n",
            "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (0.4.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow!=2.6.0,!=2.6.1,<2.7.0,>=2.2.0->alibi-detect) (3.1.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability<0.13.0,>=0.8.0->alibi-detect) (0.1.6)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability<0.13.0,>=0.8.0->alibi-detect) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability<0.13.0,>=0.8.0->alibi-detect) (4.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 39.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 471 kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (3.4.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 66.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.0.0->alibi-detect) (7.1.2)\n",
            "Building wheels for collected packages: clang, wrapt\n",
            "  Building wheel for clang (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30692 sha256=97c9e3d4e1102fa7ec5ca76f02e29cfa2f42f0bae46cfcf3392fc5e9778998ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/91/04/971b4c587cf47ae952b108949b46926f426c02832d120a082a\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68715 sha256=1936c689212758b44577b4695551ed7ab30a1621a0e509b93bec4645f2eae705\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built clang wrapt\n",
            "Installing collected packages: typing-extensions, pyyaml, wrapt, tokenizers, tensorflow-estimator, tensorboard, sacremoses, keras, huggingface-hub, flatbuffers, clang, transformers, tensorflow-probability, tensorflow, alibi-detect\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.13.3\n",
            "    Uninstalling wrapt-1.13.3:\n",
            "      Successfully uninstalled wrapt-1.13.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.15.0\n",
            "    Uninstalling tensorflow-probability-0.15.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "Successfully installed alibi-detect-0.8.0 clang-5.0 flatbuffers-1.12 huggingface-hub-0.2.1 keras-2.6.0 pyyaml-6.0 sacremoses-0.0.46 tensorboard-2.6.0 tensorflow-2.6.2 tensorflow-estimator-2.6.0 tensorflow-probability-0.12.2 tokenizers-0.10.3 transformers-4.14.1 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "keras",
                  "tensorboard",
                  "tensorflow",
                  "typing_extensions",
                  "wrapt"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from alibi_detect.od import OutlierAE\n",
        "from alibi_detect.utils.visualize import plot_instance_score, plot_feature_outlier_image"
      ],
      "metadata": {
        "id": "i72rg-awdPJ9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "r7O3X1bBe_XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PttdKLmtfL4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3gfxDil0fNWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I1QdiVU5e-2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q6l5Z7enZCvd"
      },
      "outputs": [],
      "source": [
        "def img_to_np(path, resize = True):  \n",
        "    img_array = []\n",
        "    fpaths = glob.glob(path, recursive=True)\n",
        "    for fname in fpaths:\n",
        "        img = Image.open(fname).convert(\"RGB\")\n",
        "        if(resize): img = img.resize((64,64))\n",
        "        img_array.append(np.asarray(img))\n",
        "    images = np.array(img_array)\n",
        "    return images\n",
        "  \n",
        "path_train = \"D:\\\\img\\\\capsule\\\\train\\\\**\\*.*\"\n",
        "path_test = \"D:\\\\img\\\\capsule\\\\test\\\\**\\*.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ipNsY6wpZCve"
      },
      "outputs": [],
      "source": [
        "train = img_to_np(path_train)\n",
        "test = img_to_np(path_test)\n",
        "train = train.astype('float32') / 255.\n",
        "test = test.astype('float32') / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "10fzGSHIZCve"
      },
      "outputs": [],
      "source": [
        "encoding_dim = 1024\n",
        "dense_dim = [8, 8, 128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Xdh42-tFZCvf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "f12747cb-d341-4e5d-8561-e382d423c535"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-235d7150b356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m encoder_net = tf.keras.Sequential(\n\u001b[1;32m      2\u001b[0m   [\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ],
      "source": [
        "encoder_net = tf.keras.Sequential(\n",
        "  [\n",
        "      InputLayer(input_shape=train[0].shape),\n",
        "      Conv2D(64, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "      Conv2D(128, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "      Conv2D(512, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "      Flatten(),\n",
        "      Dense(encoding_dim,)\n",
        "  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0jcLzhvZCvf"
      },
      "outputs": [],
      "source": [
        "decoder_net = tf.keras.Sequential(\n",
        "  [\n",
        "      InputLayer(input_shape=(encoding_dim,)),\n",
        "      Dense(np.prod(dense_dim)),\n",
        "      Reshape(target_shape=dense_dim),\n",
        "      Conv2DTranspose(256, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "      Conv2DTranspose(64, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
        "      Conv2DTranspose(3, 4, strides=2, padding='same', activation='sigmoid')\n",
        "  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QD1ARcVZCvf"
      },
      "outputs": [],
      "source": [
        "od = OutlierAE( threshold = 0.001,\n",
        "                encoder_net=encoder_net,\n",
        "                decoder_net=decoder_net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "typcdEtiZCvg"
      },
      "outputs": [],
      "source": [
        "adam = tf.keras.optimizers.Adam(lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvB3msfGZCvg"
      },
      "outputs": [],
      "source": [
        "od.fit(train, epochs=100, verbose=True,\n",
        "       optimizer = adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWz2yHntZCvh"
      },
      "outputs": [],
      "source": [
        "od.infer_threshold(test, threshold_perc=95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPVQUw7SZCvh"
      },
      "outputs": [],
      "source": [
        "preds = od.predict(test, outlier_type='instance',\n",
        "            return_instance_score=True,\n",
        "            return_feature_score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8SK4_wQZCvh"
      },
      "outputs": [],
      "source": [
        "for i, fpath in enumerate(glob.glob(path_test)):\n",
        "    if(preds['data']['is_outlier'][i] == 1):\n",
        "        source = fpath\n",
        "        shutil.copy(source, 'img\\\\')\n",
        "        \n",
        "filenames = [os.path.basename(x) for x in glob.glob(path_test, recursive=True)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ohnBYUMZCvi"
      },
      "outputs": [],
      "source": [
        "dict1 = {'Filename': filenames,\n",
        "     'instance_score': preds['data']['instance_score'],\n",
        "     'is_outlier': preds['data']['is_outlier']}\n",
        "     \n",
        "df = pd.DataFrame(dict1)\n",
        "df_outliers = df[df['is_outlier'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D-3YcqsZCvi"
      },
      "outputs": [],
      "source": [
        "print(df_outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcaDweyqZCvi"
      },
      "outputs": [],
      "source": [
        "recon = od.ae(test).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytpe0XgwZCvj"
      },
      "outputs": [],
      "source": [
        "plot_feature_outlier_image(preds, test, \n",
        "                           X_recon=recon,  \n",
        "                           max_instances=5,\n",
        "                           outliers_only=True,\n",
        "                           figsize=(15,15))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "alibi1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}