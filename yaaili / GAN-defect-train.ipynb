{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsoy/ALOCC-CVPR2018/blob/master/yaaili%20/%20GAN-defect-train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## https://colab.research.google.com/drive/1caC0Bz-Uj-LDznjOBA0uR5-3fJGn5LjC froom yaaili GAN-defect"
      ],
      "metadata": {
        "id": "deOU_GW05mW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "kMaIUnrvJguK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "OqpudBZAJ1du"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RjqRqI-YJ5Wo",
        "outputId": "53aa882a-002c-4b79-ab7f-18365e729ae0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XsJBuwcyJgku"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/GAN-defect"
      ],
      "metadata": {
        "id": "yukWPQj6Lbmf",
        "outputId": "7476e6e1-5639-4f72-de6e-dea237b17874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GAN-defect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xBoapYeG5gmM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.multiprocessing as mp\n",
        "import torch.distributed as dist\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision as tv\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.nn.parallel import DistributedDataParallel\n",
        "from tqdm.autonotebook import tqdm\n",
        "from model import *\n",
        "from fcn import *\n",
        "from defect import DefectAdder, NormalizeList, ToTensorList\n",
        "from utils import *\n",
        "from loss import *\n",
        "import os\n",
        "from trainer import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jp-OEjI55gmN"
      },
      "outputs": [],
      "source": [
        "class Config(object):\n",
        "    data_path = r'/content/drive/MyDrive/GAN-defect/train'\n",
        "    val_path = r'/content/drive/MyDrive/GAN-defect/val'\n",
        "    save_path = '/data/sdv2/GAN/GAN_defect/imgs/0430'\n",
        "    work_dir = '/data/sdv2/GAN/GAN_defect/workdirs/0430'\n",
        "    val_save_path = '/data/sdv2/GAN/GAN_defect/imgs/0430-val'\n",
        "\n",
        "    # data_path = r'/data/sdv2/GAN/data/gan_defect/1GE02/train'\n",
        "    # val_path = r'/data/sdv2/GAN/data/gan_defect/1GE02/val'\n",
        "    # save_path = '/data/sdv2/GAN/GAN_defect/imgs/0427-1ge02'\n",
        "    # work_dir = '/data/sdv2/GAN/GAN_defect/workdirs/0427-1ge02'\n",
        "    # val_save_path = '/data/sdv2/GAN/GAN_defect/imgs/0427-1ge02-val'\n",
        "    num_workers = 4\n",
        "    image_size = 128\n",
        "    batch_size = 16\n",
        "    max_epoch = 3\n",
        "    steps = [100, 200]\n",
        "    lrg = 1e-3\n",
        "    lrd = 1e-4\n",
        "    lrs = 1e-2\n",
        "    beta1 = 0.5\n",
        "    nBottleneck = 4000\n",
        "    nc = 3\n",
        "    ngf = 64\n",
        "    ndf = 64\n",
        "    defect_mode = 'geometry'\n",
        "    contrast_loss_weight = 1\n",
        "\n",
        "    # device settings\n",
        "    use_gpu = True\n",
        "    gpus = 1\n",
        "    nodes = 1\n",
        "    nr = 0\n",
        "    d_every = 1\n",
        "    g_every = 1\n",
        "    s_every = 5\n",
        "    s_start = 0\n",
        "    decay_every = 10\n",
        "    netd_path = '/data/sdv2/GAN/GAN_defect/workdirs/0427-1ge02/d_ckpt_e2000.pth'\n",
        "    netg_path = '/data/sdv2/GAN/GAN_defect/workdirs/0427-1ge02/g_ckpt_e2000.pth'\n",
        "    # netd_path = None\n",
        "    # netg_path = None\n",
        "    mean = (0.5, 0.5, 0.5)\n",
        "    std = (0.5, 0.5, 0.5)\n",
        "    checkpoint_interval = 100\n",
        "    debug = True\n",
        "    validate = True\n",
        "    with_segmentation = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "HZvbbMBJ5gmO"
      },
      "outputs": [],
      "source": [
        "def main(opt):\n",
        "    if opt.use_gpu and opt.gpus > 1:\n",
        "        print('distributed training')\n",
        "        os.environ['MASTER_ADDR'] = '172.27.9.82'\n",
        "        os.environ['MASTER_PORT'] = '8888'\n",
        "        mp.spawn(distributed_train, nprocs=opt.gpus, args=(opt,))\n",
        "    else:\n",
        "        print('undistributed training')\n",
        "        train(opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8hDhXLHe5gmP"
      },
      "outputs": [],
      "source": [
        "def train(opt):\n",
        "    transforms = tv.transforms.Compose([\n",
        "        tv.transforms.Resize(opt.image_size),\n",
        "        tv.transforms.CenterCrop(opt.image_size),\n",
        "        # tv.transforms.ToTensor(),\n",
        "        DefectAdder(mode=opt.defect_mode, defect_shape=('line',), normal_only=True),\n",
        "        ToTensorList(),\n",
        "        NormalizeList(opt.mean, opt.std),\n",
        "        # tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    dataset = tv.datasets.ImageFolder(opt.data_path, transform=transforms)\n",
        "    train_dataloader = DataLoader(dataset,\n",
        "                                  batch_size=opt.batch_size,\n",
        "                                  shuffle=True,\n",
        "                                  num_workers=opt.num_workers,\n",
        "                                  drop_last=True)\n",
        "    if opt.validate:\n",
        "        val_transforms = tv.transforms.Compose([\n",
        "            tv.transforms.Resize(opt.image_size),\n",
        "            tv.transforms.CenterCrop(opt.image_size),\n",
        "            # tv.transforms.ToTensor(),\n",
        "            DefectAdder(mode=opt.defect_mode, defect_shape=('line',)),\n",
        "            ToTensorList(),\n",
        "            NormalizeList(opt.mean, opt.std),\n",
        "            # tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "        val_dataset = tv.datasets.ImageFolder(opt.val_path, transform=val_transforms)\n",
        "        val_dataloader = DataLoader(val_dataset,\n",
        "                                    batch_size=opt.batch_size,\n",
        "                                    shuffle=True,\n",
        "                                    num_workers=opt.num_workers,\n",
        "                                    drop_last=True)\n",
        "    else:\n",
        "        val_dataloader = None\n",
        "    map_location = lambda storage, loc: storage\n",
        "    netd = Discriminator(opt)\n",
        "    netg = Generater(opt)\n",
        "    nets = FCN32s(n_class=2, input_channels=6)\n",
        "    if opt.use_gpu:\n",
        "        netd.cuda()\n",
        "        netg.cuda()\n",
        "        nets.cuda()\n",
        "    if opt.netd_path:\n",
        "        print('loading checkpoint for discriminator...')\n",
        "        checkpoint = modify_checkpoint(netd, torch.load(opt.netd_path, map_location=map_location)['net'])\n",
        "        netd.load_state_dict(checkpoint, strict=False)\n",
        "    if opt.netg_path:\n",
        "        print('loading checkpoint for generator...')\n",
        "        checkpoint = modify_checkpoint(netg, torch.load(opt.netg_path, map_location=map_location)['net'])\n",
        "        netg.load_state_dict(checkpoint, strict=False)\n",
        "    optimizer_g = optim.Adam(netg.parameters(), opt.lrg, betas=(opt.beta1, 0.999))\n",
        "    optimizer_d = optim.Adam(netd.parameters(), opt.lrd, betas=(opt.beta1, 0.999))\n",
        "    optimizer_s = optim.Adam(nets.parameters(), opt.lrs, betas=(opt.beta1, 0.999))\n",
        "    scheduler_g = torch.optim.lr_scheduler.MultiStepLR(optimizer_g, milestones=opt.steps, gamma=0.1)\n",
        "    scheduler_d = torch.optim.lr_scheduler.MultiStepLR(optimizer_d, milestones=opt.steps, gamma=0.1)\n",
        "    scheduler_s = torch.optim.lr_scheduler.MultiStepLR(optimizer_s, milestones=opt.steps, gamma=0.1)\n",
        "    trainer = Trainer(opt, [netd, netg, nets], [optimizer_d, optimizer_g, optimizer_s],\n",
        "                      [scheduler_d, scheduler_g, scheduler_s],\n",
        "                      train_dataloader, val_dataloader)\n",
        "    trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "C1orlh3Z5gmQ"
      },
      "outputs": [],
      "source": [
        "def distributed_train(gpu, opt):\n",
        "    rank = opt.nr * opt.gpus + gpu\n",
        "    world_size = opt.gpus * opt.nodes\n",
        "    dist.init_process_group(\n",
        "        backend='nccl',\n",
        "        init_method='env://',\n",
        "        world_size=world_size,\n",
        "        rank=rank\n",
        "    )\n",
        "    torch.cuda.set_device(gpu)\n",
        "    transforms = tv.transforms.Compose([\n",
        "        tv.transforms.Resize(opt.image_size),\n",
        "        tv.transforms.CenterCrop(opt.image_size),\n",
        "        # tv.transforms.ToTensor(),\n",
        "        DefectAdder(mode=opt.defect_mode, defect_shape=('line',), normal_only=True),\n",
        "        ToTensorList(),\n",
        "        NormalizeList(opt.mean, opt.std),\n",
        "        # tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    dataset = tv.datasets.ImageFolder(opt.data_path, transform=transforms)\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset,\n",
        "                                                                    num_replicas=world_size,\n",
        "                                                                    rank=rank)\n",
        "    train_dataloader = DataLoader(dataset,\n",
        "                                  batch_size=opt.batch_size,\n",
        "                                  shuffle=False,\n",
        "                                  num_workers=opt.num_workers,\n",
        "                                  drop_last=True,\n",
        "                                  sampler=train_sampler)\n",
        "    if opt.validate:\n",
        "        val_transforms = tv.transforms.Compose([\n",
        "            tv.transforms.Resize(opt.image_size),\n",
        "            tv.transforms.CenterCrop(opt.image_size),\n",
        "            # tv.transforms.ToTensor(),\n",
        "            DefectAdder(mode=opt.defect_mode, defect_shape=('line',)),\n",
        "            ToTensorList(),\n",
        "            NormalizeList(opt.mean, opt.std),\n",
        "            # tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "        val_dataset = tv.datasets.ImageFolder(opt.val_path, transform=val_transforms)\n",
        "        val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset,\n",
        "                                                                      num_replicas=world_size,\n",
        "                                                                      rank=rank)\n",
        "        val_dataloader = DataLoader(val_dataset,\n",
        "                                    batch_size=opt.batch_size,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=opt.num_workers,\n",
        "                                    drop_last=True,\n",
        "                                    sampler=val_sampler\n",
        "                                    )\n",
        "    else:\n",
        "        val_dataloader = None\n",
        "    map_location = lambda storage, loc: storage\n",
        "    netd = Discriminator(opt)\n",
        "    netg = Generater(opt)\n",
        "    nets = FCN32s(n_class=2, input_channels=6)\n",
        "    if opt.use_gpu:\n",
        "        netd.cuda(gpu)\n",
        "        netg.cuda(gpu)\n",
        "        nets.cuda(gpu)\n",
        "    netd = nn.parallel.DistributedDataParallel(netd, device_ids=[gpu])\n",
        "    netg = nn.parallel.DistributedDataParallel(netg, device_ids=[gpu])\n",
        "    nets = nn.parallel.DistributedDataParallel(nets, device_ids=[gpu])\n",
        "    if opt.netd_path:\n",
        "        print('loading checkpoint for discriminator...')\n",
        "        checkpoint = modify_checkpoint(netd, torch.load(opt.netd_path, map_location=map_location)['net'])\n",
        "        netd.load_state_dict(checkpoint, strict=False)\n",
        "    if opt.netg_path:\n",
        "        print('loading checkpoint for generator...')\n",
        "        checkpoint = modify_checkpoint(netg, torch.load(opt.netg_path, map_location=map_location)['net'])\n",
        "        netg.load_state_dict(checkpoint, strict=False)\n",
        "    optimizer_g = optim.Adam(netg.parameters(), opt.lrg, betas=(opt.beta1, 0.999))\n",
        "    optimizer_d = optim.Adam(netd.parameters(), opt.lrd, betas=(opt.beta1, 0.999))\n",
        "    optimizer_s = optim.Adam(nets.parameters(), opt.lrs, betas=(opt.beta1, 0.999))\n",
        "    scheduler_g = torch.optim.lr_scheduler.MultiStepLR(optimizer_g, milestones=opt.steps, gamma=0.1)\n",
        "    scheduler_d = torch.optim.lr_scheduler.MultiStepLR(optimizer_d, milestones=opt.steps, gamma=0.1)\n",
        "    scheduler_s = torch.optim.lr_scheduler.MultiStepLR(optimizer_s, milestones=opt.steps, gamma=0.1)\n",
        "    criterion = nn.BCELoss()\n",
        "    contrast_criterion = nn.MSELoss()\n",
        "    true_labels = torch.ones(opt.batch_size)\n",
        "    fake_labels = torch.zeros(opt.batch_size)\n",
        "    if opt.use_gpu:\n",
        "        criterion.cuda()\n",
        "        contrast_criterion.cuda()\n",
        "        true_labels, fake_labels = true_labels.cuda(), fake_labels.cuda()\n",
        "        # fix_noises, noises = fix_noises.cuda(), noises.cuda()\n",
        "    trainer = Trainer(opt, [netd, netg, nets], [optimizer_d, optimizer_g, optimizer_s],\n",
        "                      [scheduler_d, scheduler_g, scheduler_s],\n",
        "                      train_dataloader, val_dataloader)\n",
        "    trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ITdtUGwb5gmR",
        "outputId": "9cb54a37-c7c1-4246-b812-755209c87d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "undistributed training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-696ce04860e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-a33d5ca7cfc9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'undistributed training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-00955fe870ed>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mnets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFCN32s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mnetd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mnetg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mnets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    opt = Config()\n",
        "    main(opt)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}