{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsoy/ALOCC-CVPR2018/blob/master/Copia_de_Copia_de_177_semantic_segmentation_made_easy_using_segm_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fHqSds7pDyZ"
      },
      "source": [
        "https://youtu.be/J_XSd_u_Yew"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDNxC3BtpDyc"
      },
      "source": [
        "\n",
        "<br>\n",
        "@author: Sreenivas Bhattiprolu<br>\n",
        "Segmentation MOdels library info:<br>\n",
        "#https://github.com/qubvel/segmentation_models<br>\n",
        "#Recommended for colab execution<br>\n",
        "TensorFlow ==2.1.0<br>\n",
        "keras ==2.3.1<br>\n",
        "pip install segmentation-models<br>\n",
        "For this demo it is working on a local workstation...<br>\n",
        "Python 3.5<br>\n",
        "TensorFlow ==1.<br>\n",
        "keras ==2<br>\n",
        "Data set link: http://brainiac2.mit.edu/isbi_challenge/home<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-mjnEp6qc_b",
        "outputId": "559fc416-cb96-4fd1-964b-907bd9d2823f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: segmentation-models in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.0)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.0)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.7/dist-packages (from segmentation-models) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.18.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.5.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2021.11.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.7.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Uc08FtgOpDyd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import segmentation_models as sm\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UfS22Rx2pDyf"
      },
      "outputs": [],
      "source": [
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4ncrl6wpDyf"
      },
      "source": [
        "esizing images is optional, CNNs are ok with large images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HQvQklVypDyg"
      },
      "outputs": [],
      "source": [
        "SIZE_X = 256 #Resize images (height  = X, width = Y)\n",
        "SIZE_Y = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRYj_t38pDyg"
      },
      "source": [
        "apture training image info as a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "s2kT9xg5pDyh"
      },
      "outputs": [],
      "source": [
        "train_images = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-mYLX--xpDyi"
      },
      "outputs": [],
      "source": [
        "for directory_path in glob.glob(\"membrane/augmented_train_256/aug_img\"):\n",
        "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
        "        #print(img_path)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
        "        #img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "        #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        train_images.append(img)\n",
        "        #train_labels.append(label)\n",
        "#Convert list to array for machine learning processing        \n",
        "train_images = np.array(train_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05nz5_7LpDyi"
      },
      "source": [
        "apture mask/label info as a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gRLu8RlipDyj"
      },
      "outputs": [],
      "source": [
        "train_masks = [] \n",
        "for directory_path in glob.glob(\"membrane/augmented_train_256/aug_mask\"):\n",
        "    for mask_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
        "        mask = cv2.imread(mask_path, 0)       \n",
        "        #mask = cv2.resize(mask, (SIZE_Y, SIZE_X))\n",
        "        #mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)\n",
        "        train_masks.append(mask)\n",
        "        #train_labels.append(label)\n",
        "#Convert list to array for machine learning processing          \n",
        "train_masks = np.array(train_masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzvaxbmYpDyj"
      },
      "source": [
        "se customary x_train and y_train variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nB5_HJLtpDyk"
      },
      "outputs": [],
      "source": [
        "X = train_images\n",
        "Y = train_masks\n",
        "#Y = np.expand_dims(Y, axis=3) #May not be necessary.. leftover from previous code "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BlPZqpSIpDyk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "5fb90b4a-8c3f-4e4f-b5fd-df6b8878ebd6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-623bf3fc7a01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     n_train, n_test = _validate_shuffle_split(\n\u001b[0;32m-> 2421\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2422\u001b[0m     )\n\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2099\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m             \u001b[0;34m\"aforementioned parameters.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2102\u001b[0m         )\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cyDAxSApDyl"
      },
      "source": [
        "preprocess input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAjkxt43pDyl"
      },
      "outputs": [],
      "source": [
        "x_train = preprocess_input(x_train)\n",
        "x_val = preprocess_input(x_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F3bDXm2pDyl"
      },
      "source": [
        "define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_Eek8lZpDyl"
      },
      "outputs": [],
      "source": [
        "model = sm.Unet(BACKBONE, encoder_weights='imagenet')\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh2QoHpkpDym"
      },
      "outputs": [],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgStuar-pDym"
      },
      "outputs": [],
      "source": [
        "history=model.fit(x_train, \n",
        "          y_train,\n",
        "          batch_size=8, \n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yNzqf2fpDym"
      },
      "source": [
        "ccuracy = model.evaluate(x_val, y_val)<br>\n",
        "lot the training and validation accuracy and loss at each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovhgmGjNpDyn"
      },
      "outputs": [],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7WW1igXpDyn"
      },
      "source": [
        "odel.save('membrane.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGkzBpukpDyn"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('membrane.h5', compile=False)\n",
        "#Test on a different image\n",
        "#READ EXTERNAL IMAGE...\n",
        "test_img = cv2.imread('membrane/test/0.png', cv2.IMREAD_COLOR)       \n",
        "test_img = cv2.resize(test_img, (SIZE_Y, SIZE_X))\n",
        "test_img = cv2.cvtColor(test_img, cv2.COLOR_RGB2BGR)\n",
        "test_img = np.expand_dims(test_img, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WndXg6zYpDyo"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(test_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xshnZm8LpDyo"
      },
      "source": [
        "iew and Save segmented image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgpPpOMVpDyo"
      },
      "outputs": [],
      "source": [
        "prediction_image = prediction.reshape(mask.shape)\n",
        "plt.imshow(prediction_image, cmap='gray')\n",
        "plt.imsave('membrane/test0_segmented.jpg', prediction_image, cmap='gray')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e64947f8157c2aa87181ac205b5d4ae19bbca5f9b08d86a2860c4ac7c03cad0f"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}