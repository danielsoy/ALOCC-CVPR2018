{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "obvious-assessment",
      "metadata": {
        "id": "obvious-assessment"
      },
      "source": [
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# ResNet\n",
        "\n",
        "*Author: Pytorch Team*\n",
        "\n",
        "**Deep residual networks pre-trained on ImageNet**\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/resnet.png\" alt=\"alt\" width=\"50%\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "flying-juice",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flying-juice",
        "outputId": "556d210e-9a70-4644-dc74-4e94aae9309a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import torch\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "# or any of these variants\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "loving-liberty",
      "metadata": {
        "id": "loving-liberty"
      },
      "source": [
        "All pre-trained models expect input images normalized in the same way,\n",
        "i.e. mini-batches of 3-channel RGB images of shape `(3 x H x W)`, where `H` and `W` are expected to be at least `224`.\n",
        "The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n",
        "and `std = [0.229, 0.224, 0.225]`.\n",
        "\n",
        "Here's a sample execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "existing-extreme",
      "metadata": {
        "id": "existing-extreme"
      },
      "outputs": [],
      "source": [
        "# Download an example image from the pytorch website\n",
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "planned-communist",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "planned-communist",
        "outputId": "fad38d00-656f-4a3f-efc2-dcf3feefcdba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.5918e-02, -1.5497e+00,  3.2031e-01, -2.0585e+00, -8.5747e-01,\n",
            "         1.7843e+00,  1.4699e+00,  2.1626e+00,  4.4888e+00,  8.2885e-01,\n",
            "        -5.7819e+00, -3.4969e+00, -4.0621e+00, -4.7517e+00, -3.8072e+00,\n",
            "        -4.7243e+00, -1.2590e+00,  2.9813e-01, -2.0459e+00, -5.2885e-01,\n",
            "        -3.5982e+00, -8.1425e-01, -2.7651e+00, -1.2770e+00, -3.4182e+00,\n",
            "        -1.9048e+00, -3.0018e+00, -1.3471e+00, -1.8391e+00,  1.3937e+00,\n",
            "        -2.0114e+00, -1.4137e+00, -2.3287e+00, -1.8198e+00, -1.1914e-01,\n",
            "        -3.4102e+00, -1.6544e+00, -3.4496e+00, -2.6479e+00, -2.7407e+00,\n",
            "        -2.2193e+00, -3.6509e+00, -4.1255e+00, -5.5946e+00, -1.7519e+00,\n",
            "        -1.6900e+00, -9.8164e-01, -2.1251e+00, -3.5137e+00, -1.3320e+00,\n",
            "        -1.1335e+00, -1.1564e+00, -2.2712e-02, -8.5797e-01, -1.2919e+00,\n",
            "        -2.8682e+00,  6.6078e-01, -1.7178e+00, -1.2443e+00, -2.3362e+00,\n",
            "        -5.7818e-02, -1.9204e+00, -2.5964e+00, -1.8020e+00, -1.5125e+00,\n",
            "        -1.0843e+00, -4.0987e-01, -1.3090e+00, -9.4153e-01, -4.0615e+00,\n",
            "        -1.9027e+00, -6.0975e-01, -2.3426e+00, -2.5544e+00, -2.7568e+00,\n",
            "        -2.1587e+00, -3.0438e+00, -3.8201e+00,  1.9932e+00,  8.0768e-01,\n",
            "        -2.8857e+00, -4.6229e-01, -1.9095e+00, -1.8599e+00, -1.9991e-01,\n",
            "        -7.4707e-01, -2.3904e+00, -1.1250e+00, -2.0491e+00,  2.2938e+00,\n",
            "        -2.6377e+00, -3.6704e+00, -4.7520e+00, -2.8039e+00, -1.9299e+00,\n",
            "        -4.6468e+00, -2.5182e+00, -2.4850e+00, -3.0077e+00, -4.8836e-01,\n",
            "        -9.3521e-01, -2.6058e+00,  2.1376e+00, -2.6329e+00,  8.3506e+00,\n",
            "         8.9668e-01,  3.7531e+00, -3.4335e+00, -1.8960e+00, -4.2943e+00,\n",
            "         2.9082e-01, -2.3308e+00,  2.3836e+00,  4.2319e-02,  2.2397e-01,\n",
            "         7.5308e-01, -3.3080e+00, -1.4768e+00, -1.1792e+00, -1.9249e+00,\n",
            "        -1.8421e+00, -1.2775e+00, -1.0864e+00, -9.9565e-01,  1.5227e-01,\n",
            "        -1.4355e+00, -1.8052e+00,  1.0732e+00, -1.8634e+00,  2.6153e-01,\n",
            "        -1.5023e+00, -4.6530e+00, -1.9521e+00, -6.8744e+00, -1.6433e+00,\n",
            "        -3.2272e+00, -3.2739e+00, -3.8374e+00, -2.1751e+00, -3.5047e+00,\n",
            "        -4.7009e+00, -3.6270e+00, -4.8844e+00, -1.9901e+00,  2.6526e-01,\n",
            "        -6.7295e-01,  9.3509e-01, -2.2415e+00, -2.1363e+00, -4.7924e-01,\n",
            "        -2.6271e-01,  5.0756e+00,  4.4932e+00,  5.3031e+00,  5.1180e+00,\n",
            "         1.0446e+00,  5.5503e-02,  5.7181e+00,  2.8040e+00, -6.5414e-01,\n",
            "         7.1562e-01, -1.0806e+00, -8.4479e-01, -1.4036e+00, -4.8315e-01,\n",
            "        -4.0582e+00,  2.1610e-02, -1.7137e+00, -2.5360e-01,  5.0012e+00,\n",
            "         6.5730e+00,  3.8630e-01,  1.3999e-01,  3.1344e+00,  6.6824e+00,\n",
            "         2.2414e+00,  4.6645e-01,  3.2950e+00, -8.5229e-01,  1.1061e+00,\n",
            "         1.6826e+00,  2.9597e-02,  2.7676e+00,  1.0094e+00,  3.2906e+00,\n",
            "         6.0673e+00,  7.0698e+00,  5.1815e-01,  3.6306e+00,  2.7650e+00,\n",
            "         3.2205e+00, -9.3784e-01,  6.9483e+00,  4.2839e+00,  2.6159e+00,\n",
            "         1.6080e+00,  4.3847e-01,  1.0887e+00, -3.5319e-01,  6.1558e+00,\n",
            "         2.6472e+00,  1.6073e+00,  2.6772e+00,  1.0351e+01,  2.5268e+00,\n",
            "         8.3449e-01, -1.3505e+00,  5.1928e+00,  2.9642e+00, -5.6726e-01,\n",
            "        -1.4320e+00,  2.9360e-02,  2.4520e+00,  3.0417e-01, -7.7818e-01,\n",
            "         1.6603e+00,  1.9853e+00,  2.0598e+00,  2.6966e-01, -1.8801e-01,\n",
            "         2.7371e-01, -1.7507e+00,  8.8910e+00,  8.1109e+00,  7.3231e+00,\n",
            "         2.8657e+00,  3.7827e+00,  4.1981e+00,  5.8150e+00,  6.1472e+00,\n",
            "         6.4172e+00,  7.6086e+00,  6.9847e+00,  2.9936e+00, -5.2758e-01,\n",
            "         5.5965e+00,  1.4392e+00, -3.9503e-01,  2.0425e+00,  1.8702e+00,\n",
            "         2.0413e+00,  2.0421e-01,  6.4460e-01, -4.0614e-01,  2.5661e+00,\n",
            "         1.2417e+00,  1.4611e+00,  4.1676e+00,  1.0818e+01,  8.7367e+00,\n",
            "         9.9064e+00,  2.8385e+00,  2.0287e-01,  1.7976e+00,  2.3186e+00,\n",
            "         2.5285e+00,  4.5001e+00,  1.1026e+01,  1.6273e+01,  1.1215e+01,\n",
            "         7.8094e+00,  1.0740e+01, -9.9220e-02,  5.7142e+00,  4.7237e+00,\n",
            "         3.3941e+00,  3.0939e+00,  3.8398e+00, -8.0395e-01,  8.1740e+00,\n",
            "         1.3279e+01,  3.4679e+00,  4.4451e+00,  5.5244e+00,  4.1509e+00,\n",
            "        -1.9327e-01,  1.3198e+00,  5.0951e+00,  4.9228e+00,  1.3313e+01,\n",
            "         4.6688e+00,  4.1280e+00,  3.8479e+00,  6.4162e+00,  6.1095e+00,\n",
            "         3.3097e+00,  2.3572e+00,  6.8445e+00,  9.5434e-01,  2.8592e+00,\n",
            "        -1.1244e+00,  1.5085e+00,  1.7631e+00,  1.2531e+00,  2.8554e+00,\n",
            "         1.7463e+00,  6.7799e+00,  2.5125e-01, -1.3342e+00,  5.1050e-01,\n",
            "        -2.8969e+00, -8.2496e-01, -2.9130e+00, -3.0456e+00, -1.1142e+00,\n",
            "        -2.8026e+00, -1.4486e+00, -6.7262e-01, -4.2247e+00, -1.7623e+00,\n",
            "         4.3570e-01, -1.4014e+00, -1.5380e+00, -1.5596e+00,  1.6334e+00,\n",
            "        -2.3892e+00, -2.9759e+00, -4.3734e-01, -5.5001e-01, -6.1542e+00,\n",
            "        -4.0857e+00, -2.3556e+00, -3.9536e+00, -2.8767e+00, -4.4984e-01,\n",
            "        -1.7370e+00, -1.6374e+00,  2.1360e+00, -8.5107e-01, -1.5195e-02,\n",
            "         2.7704e+00,  5.3773e+00,  5.9535e+00,  5.4208e+00,  2.8854e+00,\n",
            "         3.7443e-01,  1.6293e+00,  4.4487e-01,  3.2411e+00,  9.7582e-01,\n",
            "         2.5311e-02,  3.1032e+00, -2.7099e-01, -2.7836e+00, -3.1692e+00,\n",
            "         8.1342e-01, -6.5196e-01, -2.9631e+00,  2.6037e+00, -9.6922e-01,\n",
            "        -9.5742e-01, -4.7068e+00, -3.5804e+00,  2.2840e-01, -2.1702e+00,\n",
            "         6.5002e+00,  5.7219e+00,  2.9793e+00,  6.4611e+00,  5.4975e+00,\n",
            "        -5.2996e-01,  4.7048e+00,  2.8008e+00, -3.6092e-03, -1.3491e+00,\n",
            "        -4.5432e-01, -5.6187e-01, -1.6322e+00,  2.1284e+00, -1.4569e+00,\n",
            "        -1.1623e-03,  9.0620e-01,  1.6598e+00,  2.0624e+00,  1.0829e+00,\n",
            "        -8.1911e-01, -3.6819e+00,  2.5470e+00,  1.4180e+00,  5.3964e-01,\n",
            "         1.0845e+00, -9.6097e-02,  4.6213e-01,  1.0754e+00,  7.6536e-02,\n",
            "        -2.6620e+00, -4.3084e+00,  3.6672e+00,  5.1774e+00, -6.1791e-01,\n",
            "        -1.5415e+00,  7.3573e-01, -3.7433e+00, -2.9970e+00, -5.4823e-01,\n",
            "        -1.9206e+00, -3.7729e+00, -2.9885e+00, -9.2415e-01, -4.2514e-01,\n",
            "        -8.8965e-01, -5.8486e-01, -6.5334e-01, -4.9157e+00, -2.8375e+00,\n",
            "         3.4268e-01, -2.2503e+00, -2.7347e-01, -2.4050e+00, -5.2626e-01,\n",
            "        -2.6042e+00,  3.2445e-01,  4.0667e+00, -2.1196e+00, -5.1543e-01,\n",
            "        -1.7745e+00, -2.0623e+00, -6.6496e-01, -1.4364e+00,  9.8571e-01,\n",
            "         5.9955e-03, -9.6792e-01, -6.0225e-01, -1.4000e+00, -2.0710e+00,\n",
            "         1.1075e+00, -1.9486e+00,  2.2065e+00,  2.9294e+00,  1.8658e+00,\n",
            "        -2.8881e+00, -4.3115e-01, -1.3990e+00, -3.7418e-01,  7.7500e-01,\n",
            "         3.9198e+00, -7.5727e-01, -1.8530e-01, -1.6255e+00,  2.2081e+00,\n",
            "         1.5956e+00,  6.9980e-02,  3.9040e-01,  4.6344e-01,  5.9016e-01,\n",
            "        -9.2835e-02, -5.1500e-01, -1.3637e+00, -1.5078e-01, -5.6912e-01,\n",
            "         2.4666e+00, -1.7132e+00, -1.6860e+00, -3.2602e-01, -8.4201e-01,\n",
            "         2.1154e+00, -8.4045e-02,  1.7860e+00, -6.3439e-01, -7.4765e-01,\n",
            "         4.2897e-01, -5.1184e-01,  3.4125e+00,  5.7139e+00, -1.2795e+00,\n",
            "        -1.6497e+00, -2.5285e+00, -3.1734e+00, -1.0102e+00,  9.4759e-01,\n",
            "         9.9308e-01, -1.0922e-01,  2.5839e+00,  1.4922e+00, -1.2992e+00,\n",
            "        -2.8170e-01, -8.6435e-01, -1.4672e-01,  1.7313e+00,  2.4510e+00,\n",
            "        -7.3570e-01, -2.5554e+00, -1.9142e+00,  1.6980e-01,  3.2632e-01,\n",
            "        -1.3443e+00, -1.5297e+00, -7.6557e-01, -7.8684e-01,  1.0074e+00,\n",
            "        -1.2130e+00,  1.4810e+00, -2.7207e-01, -1.3605e+00, -1.7983e-01,\n",
            "        -1.1730e+00,  2.3959e+00, -6.8000e-01, -2.6903e+00,  7.7480e-02,\n",
            "        -3.4509e+00,  1.2124e+00,  1.2672e+00, -1.0999e+00,  2.8033e-01,\n",
            "        -9.9973e-01, -2.0026e+00,  7.5466e-01,  2.4307e+00, -1.7247e+00,\n",
            "        -7.9773e-02,  8.8518e-01, -4.0756e-01, -2.4663e+00, -1.2027e+00,\n",
            "         5.4814e-01, -1.6021e+00, -2.4280e+00,  5.5575e-01, -3.8049e-01,\n",
            "        -2.0516e+00,  3.3770e+00,  3.1903e+00,  6.7000e-01, -6.8531e-01,\n",
            "        -9.4827e-01, -3.6431e-01, -7.6098e-01,  2.1828e+00,  8.0119e-01,\n",
            "        -1.0046e+00, -1.2824e+00, -2.3656e+00, -3.1687e+00,  2.1272e+00,\n",
            "         1.2672e-01, -1.6892e+00,  2.6973e+00, -3.0822e+00,  4.0324e+00,\n",
            "        -2.8332e+00,  3.3901e-01,  1.0081e-02,  5.2546e-01,  1.9752e+00,\n",
            "        -7.1673e-02,  2.9041e-01, -2.9111e+00, -2.4014e+00,  7.0131e-01,\n",
            "        -4.1842e+00,  4.7370e-01,  1.1472e+00, -6.1524e-01, -7.0896e-01,\n",
            "        -3.9985e-01, -3.3716e-01, -6.5772e-01, -2.2189e+00,  1.5345e+00,\n",
            "         1.2745e+00,  2.7751e-01, -2.2735e+00, -5.5896e-01, -3.7202e+00,\n",
            "        -2.9080e+00, -6.8846e-01,  9.7099e-02,  1.8662e+00, -8.5187e-01,\n",
            "        -8.4573e-01, -3.8525e+00,  3.4326e-01,  2.5432e-01,  2.6882e+00,\n",
            "         2.5991e-01, -2.0000e+00,  5.3708e-01,  1.0960e+00, -1.3279e+00,\n",
            "         1.4837e+00, -5.9335e-01, -2.0439e+00, -1.2370e+00,  1.0513e+00,\n",
            "         6.4954e-01, -6.2647e-02,  1.2370e+00,  6.8368e-01,  3.8259e+00,\n",
            "        -1.7971e+00, -6.7278e-01, -2.5600e+00, -1.6512e+00,  1.1806e+00,\n",
            "        -1.2924e+00,  2.2586e+00, -4.0487e-01, -1.1882e+00, -2.3765e+00,\n",
            "         7.9954e-01, -9.1990e-01, -1.6126e+00, -1.9355e+00, -3.9238e+00,\n",
            "        -2.1017e+00,  2.1352e+00, -2.5646e-01,  4.8958e-01, -6.0499e-01,\n",
            "         1.1564e+00,  1.8465e+00, -4.0932e+00,  2.7047e-01, -2.1523e-01,\n",
            "         1.3753e+00, -1.4033e+00, -1.0388e+00,  4.7860e-02, -1.2730e-01,\n",
            "         3.2859e-01,  1.8630e+00,  3.2699e+00, -3.5368e-01, -2.1416e+00,\n",
            "        -4.3183e-01,  7.7666e-01,  3.7304e-02, -2.0635e+00,  3.1160e-01,\n",
            "         1.6417e+00,  2.6682e+00,  2.7170e-01,  8.3577e-01, -2.9818e+00,\n",
            "        -2.4503e-01,  2.4742e-01,  1.3297e-01, -4.3418e-01, -4.3046e-01,\n",
            "         6.5773e-01,  2.1311e+00, -3.2655e+00, -5.1050e-01,  4.9343e-01,\n",
            "        -1.8940e+00,  1.8291e+00, -1.6717e+00,  6.3228e-01, -1.6439e+00,\n",
            "        -1.6570e+00, -1.1207e-03, -6.8659e-01,  2.0163e+00, -4.9133e-01,\n",
            "         7.9273e-01, -6.5997e-01, -1.4483e+00,  5.7451e-01,  2.2929e-01,\n",
            "        -3.0037e-01, -2.0798e+00, -9.1574e-01, -1.9492e+00,  8.3745e-01,\n",
            "         1.2692e+00, -9.1458e-01,  5.4567e-01, -3.6889e+00, -9.1367e-01,\n",
            "         1.9861e+00, -2.5311e-01,  2.8521e-01,  2.0949e+00,  1.2086e+00,\n",
            "         2.1154e-01,  3.4622e+00,  9.5273e-02, -8.0216e-01,  2.7265e-01,\n",
            "         1.2197e+00,  7.2029e-01, -2.8354e+00, -2.7143e+00,  4.7934e-01,\n",
            "        -1.8512e+00,  2.9761e-01, -4.1026e+00,  1.8249e-01, -7.9936e-01,\n",
            "        -1.7338e+00, -9.6721e-01, -5.8127e-01, -8.2822e-01, -9.8597e-02,\n",
            "        -5.0435e-01,  1.5545e+00,  1.4904e+00, -1.2979e+00, -1.0826e-01,\n",
            "         2.9883e+00, -1.3630e+00, -3.7239e+00,  9.1957e-01, -2.5768e+00,\n",
            "        -3.0649e+00,  1.3365e+00, -1.4009e+00, -3.5322e-01, -1.1704e+00,\n",
            "        -7.4978e-01, -2.5903e-01, -6.0258e-01, -1.5579e+00,  1.3899e+00,\n",
            "        -2.3793e+00,  1.9803e+00,  3.3006e-01, -1.0206e-01,  2.4416e+00,\n",
            "         1.2657e+00, -6.6137e-01,  2.2869e+00,  1.8482e+00, -2.9063e+00,\n",
            "        -5.7493e-01, -5.1072e+00, -2.6364e+00,  2.1372e+00, -1.3472e+00,\n",
            "        -2.2591e+00,  4.3973e+00, -2.2593e+00, -1.0246e+00, -3.2030e+00,\n",
            "         6.7143e-01, -1.9926e+00, -2.0654e-01,  4.0617e-01, -2.9339e+00,\n",
            "         1.5753e+00, -9.1893e-01,  1.1542e+00, -9.1348e-01, -1.2591e+00,\n",
            "        -1.9500e+00,  1.0347e+00,  8.3912e-01,  1.6410e+00,  1.3352e+00,\n",
            "         7.9203e-01,  7.8801e-01,  1.2226e+00,  1.3795e+00, -7.8040e-01,\n",
            "        -1.3666e+00,  5.3833e+00,  5.1338e-01,  4.9046e-01,  5.2560e-01,\n",
            "         7.3350e-01,  2.2732e+00, -1.3203e+00,  9.3211e-01, -1.6302e+00,\n",
            "         2.4191e-01, -2.4871e-01, -4.8620e-01,  2.1138e+00,  1.4489e+00,\n",
            "         3.7367e-01,  1.4004e+00,  1.5152e+00, -3.6104e-01,  2.9181e-01,\n",
            "        -9.4115e-01, -2.2436e+00, -4.9276e-01, -4.5846e-01, -2.1174e+00,\n",
            "        -2.6535e+00, -4.2171e-01,  1.4914e+00,  6.6903e-01,  1.0808e+00,\n",
            "        -2.9792e-01,  1.3667e+00,  7.1145e-01,  2.7971e-01,  3.5886e-02,\n",
            "        -1.5736e+00,  6.9129e-01,  1.3083e+00, -6.9339e-01,  8.5358e-02,\n",
            "        -4.8843e-01, -1.4164e+00,  2.3650e+00, -8.0814e-01,  7.6429e-01,\n",
            "        -4.9398e+00, -6.1574e-01, -4.6486e-01, -2.4251e+00,  1.1547e+00,\n",
            "         6.3762e+00,  9.0707e-01, -4.1598e-01, -1.3366e+00,  2.3717e-01,\n",
            "         1.4613e+00,  2.6384e+00, -1.3068e+00,  8.5315e-01, -3.5892e-01,\n",
            "        -9.9009e-01, -1.2835e+00,  5.5976e-01,  2.0848e-02, -8.9666e-01,\n",
            "        -6.9401e-01, -1.9417e+00, -6.7528e-01,  1.2534e+00,  1.3382e+00,\n",
            "         8.7609e-01, -4.7604e-01,  1.7552e+00,  5.1028e-01, -1.3920e+00,\n",
            "        -8.7654e-01,  1.1599e+00, -1.0186e+00, -1.3284e+00, -3.7167e-01,\n",
            "        -1.0469e+00,  5.7449e-01,  1.5574e+00,  1.8519e+00, -4.1095e-01,\n",
            "        -2.0581e-01,  1.0532e+00,  1.8591e+00,  4.5595e-01,  9.1578e-01,\n",
            "         1.1539e+00, -1.4320e+00, -5.3197e-01, -1.4754e+00, -1.0053e+00,\n",
            "         1.2264e+00,  1.5214e+00,  5.0184e+00, -1.5203e+00, -5.4169e-01,\n",
            "        -6.5428e-01, -1.8736e+00, -3.6343e+00, -1.0429e+00,  7.0413e-02,\n",
            "        -2.3703e+00,  2.4605e+00, -1.3011e-01, -1.7982e+00, -7.5531e-01,\n",
            "        -1.0359e+00, -1.3380e+00, -2.9617e-01, -8.2643e-01,  2.7119e-01,\n",
            "         1.5884e+00, -7.2461e-01, -2.9711e-01, -9.3042e-01, -2.4289e+00,\n",
            "        -9.2284e-01,  4.7528e+00, -1.6790e+00,  8.6679e-01,  7.8209e-01,\n",
            "         1.6629e+00, -1.0685e+00,  1.3574e+00, -8.2427e-01, -1.9540e+00,\n",
            "         4.4793e-01, -2.2733e+00, -1.9748e+00, -1.3135e+00,  7.5045e-02,\n",
            "        -6.2613e-01, -1.2929e+00, -7.9225e-01,  1.4181e-01, -5.3668e-01,\n",
            "        -3.7515e+00,  2.5790e+00,  2.9518e+00,  1.1170e+00, -7.2461e-02,\n",
            "        -1.0601e+00,  1.7500e-01,  1.4925e+00, -1.3864e+00,  1.2885e+00,\n",
            "        -1.8532e+00, -2.2471e+00,  2.7473e-01, -2.0507e+00, -5.4334e-01,\n",
            "         8.9407e-01,  7.9924e-01,  1.3935e+00, -1.7301e-01, -5.9534e-01,\n",
            "         8.0483e-01, -1.3372e-01, -3.2294e+00, -2.1450e-01, -1.5620e+00,\n",
            "        -2.2868e+00, -3.0804e-01, -4.4390e+00, -6.2412e-01, -2.5382e+00,\n",
            "        -2.4722e+00, -3.3123e+00, -2.8575e+00, -2.9188e+00,  3.9108e+00,\n",
            "        -2.2020e+00, -2.0254e+00, -5.1858e-01, -4.8108e+00, -2.6819e+00,\n",
            "         7.0438e-01, -3.2433e-01,  8.4757e-01,  1.2196e+00,  1.4949e+00,\n",
            "        -1.9164e+00, -3.8725e+00, -4.3444e-01,  2.0204e+00, -2.2128e+00,\n",
            "        -3.7765e+00, -3.2417e+00, -1.0154e+00,  1.8904e+00,  4.7873e-01,\n",
            "        -2.6042e+00, -2.1485e+00, -2.8178e+00, -1.2955e+00, -1.0276e+00,\n",
            "        -2.7621e+00, -1.6165e+00, -4.1203e-01, -1.9367e-01, -2.4879e+00,\n",
            "        -1.3851e+00,  7.6087e-01, -2.6262e+00, -2.1398e+00, -5.1703e+00,\n",
            "        -2.3795e+00, -4.5068e-01, -4.3725e+00, -2.3891e-01, -8.7406e-01,\n",
            "         4.7021e-01,  1.5145e+00, -1.1402e+00, -3.5778e+00, -1.3159e-01,\n",
            "         2.2065e+00, -1.6685e+00,  7.5954e-01, -1.0781e+00, -7.7719e-01,\n",
            "        -6.3172e-01,  1.1631e-01,  1.1369e+00, -1.4187e+00, -8.3359e-01,\n",
            "        -1.6156e+00, -2.2305e+00,  6.9370e-01, -3.4886e+00, -1.4845e+00,\n",
            "        -1.3031e+00, -1.8285e-01, -5.2394e-01, -5.7335e+00, -1.8339e+00,\n",
            "        -6.5606e-01, -1.8088e+00, -2.9126e+00,  5.6032e-01,  2.5117e+00],\n",
            "       device='cuda:0')\n",
            "tensor([7.6952e-08, 1.6081e-08, 1.0433e-07, 9.6676e-09, 3.2130e-08, 4.5104e-07,\n",
            "        3.2936e-07, 6.5847e-07, 6.7415e-06, 1.7349e-07, 2.3349e-10, 2.2942e-09,\n",
            "        1.3037e-09, 6.5414e-10, 1.6821e-09, 6.7231e-10, 2.1504e-08, 1.0204e-07,\n",
            "        9.7905e-09, 4.4630e-08, 2.0732e-09, 3.3550e-08, 4.7693e-09, 2.1121e-08,\n",
            "        2.4821e-09, 1.1274e-08, 3.7640e-09, 1.9692e-08, 1.2039e-08, 3.0521e-07,\n",
            "        1.0133e-08, 1.8423e-08, 7.3788e-09, 1.2274e-08, 6.7231e-08, 2.5019e-09,\n",
            "        1.4481e-08, 2.4052e-09, 5.3622e-09, 4.8868e-09, 8.2313e-09, 1.9667e-09,\n",
            "        1.2236e-09, 2.8159e-10, 1.3136e-08, 1.3975e-08, 2.8379e-08, 9.0447e-09,\n",
            "        2.2558e-09, 1.9991e-08, 2.4380e-08, 2.3829e-08, 7.4036e-08, 3.2114e-08,\n",
            "        2.0808e-08, 4.3020e-09, 1.4665e-07, 1.3592e-08, 2.1822e-08, 7.3231e-09,\n",
            "        7.1482e-08, 1.1099e-08, 5.6456e-09, 1.2495e-08, 1.6690e-08, 2.5611e-08,\n",
            "        5.0270e-08, 2.0456e-08, 2.9540e-08, 1.3045e-09, 1.1297e-08, 4.1162e-08,\n",
            "        7.2767e-09, 5.8877e-09, 4.8088e-09, 8.7458e-09, 3.6092e-09, 1.6606e-09,\n",
            "        5.5582e-07, 1.6986e-07, 4.2273e-09, 4.7702e-08, 1.1221e-08, 1.1791e-08,\n",
            "        6.2014e-08, 3.5881e-08, 6.9368e-09, 2.4589e-08, 9.7591e-09, 7.5075e-07,\n",
            "        5.4170e-09, 1.9288e-09, 6.5393e-10, 4.5878e-09, 1.0994e-08, 7.2648e-10,\n",
            "        6.1046e-09, 6.3108e-09, 3.7417e-09, 4.6475e-08, 2.9727e-08, 5.5929e-09,\n",
            "        6.4218e-07, 5.4434e-09, 3.2057e-04, 1.8567e-07, 3.2304e-06, 2.4443e-09,\n",
            "        1.1373e-08, 1.0335e-09, 1.0130e-07, 7.3633e-09, 8.2131e-07, 7.9011e-08,\n",
            "        9.4750e-08, 1.6083e-07, 2.7711e-09, 1.7296e-08, 2.3292e-08, 1.1049e-08,\n",
            "        1.2003e-08, 2.1110e-08, 2.5556e-08, 2.7984e-08, 8.8194e-08, 1.8025e-08,\n",
            "        1.2454e-08, 2.2151e-07, 1.1750e-08, 9.8376e-08, 1.6861e-08, 7.2198e-10,\n",
            "        1.0752e-08, 7.8303e-11, 1.4643e-08, 3.0045e-09, 2.8674e-09, 1.6322e-09,\n",
            "        8.6032e-09, 2.2764e-09, 6.8824e-10, 2.0143e-09, 5.7285e-10, 1.0352e-08,\n",
            "        9.8743e-08, 3.8641e-08, 1.9294e-07, 8.0510e-09, 8.9437e-09, 4.6901e-08,\n",
            "        5.8239e-08, 1.2124e-05, 6.7712e-06, 1.5220e-05, 1.2648e-05, 2.1527e-07,\n",
            "        8.0060e-08, 2.3050e-05, 1.2505e-06, 3.9375e-08, 1.5492e-07, 2.5704e-08,\n",
            "        3.2540e-08, 1.8609e-08, 4.6718e-08, 1.3088e-09, 7.7392e-08, 1.3648e-08,\n",
            "        5.8772e-08, 1.1254e-05, 5.4192e-05, 1.1145e-07, 8.7117e-08, 1.7401e-06,\n",
            "        6.0454e-05, 7.1242e-07, 1.2075e-07, 2.0431e-06, 3.2297e-08, 2.2893e-07,\n",
            "        4.0745e-07, 7.8012e-08, 1.2057e-06, 2.0782e-07, 2.0343e-06, 3.2683e-05,\n",
            "        8.9056e-05, 1.2716e-07, 2.8581e-06, 1.2026e-06, 1.8966e-06, 2.9649e-08,\n",
            "        7.8874e-05, 5.4927e-06, 1.0360e-06, 3.7813e-07, 1.1742e-07, 2.2497e-07,\n",
            "        5.3201e-08, 3.5705e-05, 1.0690e-06, 3.7789e-07, 1.1015e-06, 2.3704e-03,\n",
            "        9.4771e-07, 1.7447e-07, 1.9623e-08, 1.3630e-05, 1.4677e-06, 4.2949e-08,\n",
            "        1.8088e-08, 7.7994e-08, 8.7944e-07, 1.0266e-07, 3.4781e-08, 3.9846e-07,\n",
            "        5.5148e-07, 5.9410e-07, 9.9179e-08, 6.2756e-08, 9.9582e-08, 1.3152e-08,\n",
            "        5.5033e-04, 2.5226e-04, 1.1473e-04, 1.3300e-06, 3.3273e-06, 5.0411e-06,\n",
            "        2.5394e-05, 3.5401e-05, 4.6372e-05, 1.5265e-04, 8.1799e-05, 1.5115e-06,\n",
            "        4.4687e-08, 2.0411e-05, 3.1942e-07, 5.1021e-08, 5.8395e-07, 4.9148e-07,\n",
            "        5.8321e-07, 9.2896e-08, 1.4430e-07, 5.0458e-08, 9.8570e-07, 2.6215e-07,\n",
            "        3.2649e-07, 4.8896e-06, 3.7817e-03, 4.7163e-04, 1.5191e-03, 1.2944e-06,\n",
            "        9.2771e-08, 4.5708e-07, 7.6959e-07, 9.4933e-07, 6.8182e-06, 4.6520e-03,\n",
            "        8.8462e-01, 5.6213e-03, 1.8660e-04, 3.4972e-03, 6.8583e-08, 2.2959e-05,\n",
            "        8.5271e-06, 2.2560e-06, 1.6710e-06, 3.5232e-06, 3.3897e-08, 2.6867e-04,\n",
            "        4.4276e-02, 2.4287e-06, 6.4532e-06, 1.8991e-05, 4.8086e-06, 6.2427e-08,\n",
            "        2.8345e-07, 1.2362e-05, 1.0406e-05, 4.5805e-02, 8.0716e-06, 4.6999e-06,\n",
            "        3.5515e-06, 4.6326e-05, 3.4092e-05, 2.0735e-06, 7.9991e-07, 7.1097e-05,\n",
            "        1.9669e-07, 1.3215e-06, 2.4602e-08, 3.4234e-07, 4.4160e-07, 2.6518e-07,\n",
            "        1.3164e-06, 4.3421e-07, 6.6649e-05, 9.7370e-08, 1.9947e-08, 1.2619e-07,\n",
            "        4.1800e-09, 3.3192e-08, 4.1135e-09, 3.6025e-09, 2.4855e-08, 4.5934e-09,\n",
            "        1.7790e-08, 3.8654e-08, 1.1080e-09, 1.3000e-08, 1.1709e-07, 1.8651e-08,\n",
            "        1.6269e-08, 1.5922e-08, 3.8787e-07, 6.9450e-09, 3.8629e-09, 4.8908e-08,\n",
            "        4.3696e-08, 1.6091e-10, 1.2733e-09, 7.1830e-09, 1.4531e-09, 4.2657e-09,\n",
            "        4.8300e-08, 1.3334e-08, 1.4730e-08, 6.4116e-07, 3.2337e-08, 7.4595e-08,\n",
            "        1.2091e-06, 1.6392e-05, 2.9166e-05, 1.7121e-05, 1.3565e-06, 1.1013e-07,\n",
            "        3.8627e-07, 1.1817e-07, 1.9361e-06, 2.0096e-07, 7.7679e-08, 1.6867e-06,\n",
            "        5.7759e-08, 4.6816e-09, 3.1838e-09, 1.7083e-07, 3.9461e-08, 3.9123e-09,\n",
            "        1.0235e-06, 2.8733e-08, 2.9074e-08, 6.8419e-10, 2.1105e-09, 9.5171e-08,\n",
            "        8.6461e-09, 5.0385e-05, 2.3136e-05, 1.4900e-06, 4.8456e-05, 1.8486e-05,\n",
            "        4.4581e-08, 8.3668e-06, 1.2465e-06, 7.5464e-08, 1.9652e-08, 4.8084e-08,\n",
            "        4.3181e-08, 1.4806e-08, 6.3628e-07, 1.7643e-08, 7.5649e-08, 1.8744e-07,\n",
            "        3.9823e-07, 5.9566e-07, 2.2366e-07, 3.3387e-08, 1.9067e-09, 9.6707e-07,\n",
            "        3.1272e-07, 1.2992e-07, 2.2403e-07, 6.8798e-08, 1.2023e-07, 2.2199e-07,\n",
            "        8.1761e-08, 5.2871e-09, 1.0190e-09, 2.9646e-06, 1.3422e-05, 4.0828e-08,\n",
            "        1.6212e-08, 1.5806e-07, 1.7931e-09, 3.7820e-09, 4.3774e-08, 1.1097e-08,\n",
            "        1.7408e-09, 3.8143e-09, 3.0058e-08, 4.9508e-08, 3.1113e-08, 4.2200e-08,\n",
            "        3.9406e-08, 5.5520e-10, 4.4359e-09, 1.0669e-07, 7.9804e-09, 5.7616e-08,\n",
            "        6.8366e-09, 4.4746e-08, 5.6015e-09, 1.0476e-07, 4.4204e-06, 9.0948e-09,\n",
            "        4.5233e-08, 1.2843e-08, 9.6310e-09, 3.8951e-08, 1.8009e-08, 2.0295e-07,\n",
            "        7.6193e-08, 2.8770e-08, 4.1472e-08, 1.8677e-08, 9.5471e-09, 2.2923e-07,\n",
            "        1.0790e-08, 6.8799e-07, 1.4175e-06, 4.8934e-07, 4.2172e-09, 4.9211e-08,\n",
            "        1.8696e-08, 5.2096e-08, 1.6440e-07, 3.8163e-06, 3.5517e-08, 6.2927e-08,\n",
            "        1.4907e-08, 6.8912e-07, 3.7347e-07, 8.1227e-08, 1.1191e-07, 1.2039e-07,\n",
            "        1.3665e-07, 6.9023e-08, 4.5253e-08, 1.9367e-08, 6.5137e-08, 4.2869e-08,\n",
            "        8.9237e-07, 1.3655e-08, 1.4030e-08, 5.4666e-08, 3.2631e-08, 6.2811e-07,\n",
            "        6.9632e-08, 4.5184e-07, 4.0160e-08, 3.5860e-08, 1.1631e-07, 4.5396e-08,\n",
            "        2.2979e-06, 2.2952e-05, 2.1068e-08, 1.4549e-08, 6.0421e-09, 3.1703e-09,\n",
            "        2.7580e-08, 1.9536e-07, 2.0446e-07, 6.7901e-08, 1.0035e-06, 3.3680e-07,\n",
            "        2.0658e-08, 5.7143e-08, 3.1910e-08, 6.5401e-08, 4.2775e-07, 8.7859e-07,\n",
            "        3.6291e-08, 5.8816e-09, 1.1168e-08, 8.9754e-08, 1.0496e-07, 1.9747e-08,\n",
            "        1.6404e-08, 3.5223e-08, 3.4482e-08, 2.0741e-07, 2.2517e-08, 3.3304e-07,\n",
            "        5.7697e-08, 1.9429e-08, 6.3272e-08, 2.3435e-08, 8.3142e-07, 3.8370e-08,\n",
            "        5.1397e-09, 8.1839e-08, 2.4021e-09, 2.5460e-07, 2.6894e-07, 2.5213e-08,\n",
            "        1.0024e-07, 2.7870e-08, 1.0223e-08, 1.6108e-07, 8.6088e-07, 1.3499e-08,\n",
            "        6.9930e-08, 1.8354e-07, 5.0386e-08, 6.4302e-09, 2.2750e-08, 1.3103e-07,\n",
            "        1.5259e-08, 6.6810e-09, 1.3203e-07, 5.1768e-08, 9.7349e-09, 2.2177e-06,\n",
            "        1.8400e-06, 1.4801e-07, 3.8167e-08, 2.9341e-08, 5.2613e-08, 3.5385e-08,\n",
            "        6.7187e-07, 1.6876e-07, 2.7735e-08, 2.1007e-08, 7.1109e-09, 3.1855e-09,\n",
            "        6.3554e-07, 8.5969e-08, 1.3986e-08, 1.1239e-06, 3.4731e-09, 4.2715e-06,\n",
            "        4.4552e-09, 1.0630e-07, 7.6505e-08, 1.2809e-07, 5.4594e-07, 7.0499e-08,\n",
            "        1.0126e-07, 4.1211e-09, 6.8611e-09, 1.5272e-07, 1.1538e-09, 1.2163e-07,\n",
            "        2.3852e-07, 4.0937e-08, 3.7275e-08, 5.0776e-08, 5.4061e-08, 3.9234e-08,\n",
            "        8.2350e-09, 3.5136e-07, 2.7092e-07, 9.9961e-08, 7.7971e-09, 4.3307e-08,\n",
            "        1.8350e-09, 4.1342e-09, 3.8046e-08, 8.3460e-08, 4.8952e-07, 3.2311e-08,\n",
            "        3.2510e-08, 1.6076e-09, 1.0675e-07, 9.7670e-08, 1.1137e-06, 9.8217e-08,\n",
            "        1.0250e-08, 1.2959e-07, 2.2663e-07, 2.0074e-08, 3.3393e-07, 4.1843e-08,\n",
            "        9.8101e-09, 2.1982e-08, 2.1672e-07, 1.4501e-07, 7.1138e-08, 2.6094e-07,\n",
            "        1.5005e-07, 3.4744e-06, 1.2556e-08, 3.8648e-08, 5.8549e-09, 1.4528e-08,\n",
            "        2.4662e-07, 2.0797e-08, 7.2481e-07, 5.0522e-08, 2.3083e-08, 7.0340e-09,\n",
            "        1.6848e-07, 3.0186e-08, 1.5100e-08, 1.0933e-08, 1.4971e-09, 9.2587e-09,\n",
            "        6.4063e-07, 5.8604e-08, 1.2358e-07, 4.1358e-08, 2.4072e-07, 4.7998e-07,\n",
            "        1.2637e-09, 9.9260e-08, 6.1071e-08, 2.9964e-07, 1.8615e-08, 2.6801e-08,\n",
            "        7.9450e-08, 6.6685e-08, 1.0520e-07, 4.8797e-07, 1.9925e-06, 5.3175e-08,\n",
            "        8.8970e-09, 4.9178e-08, 1.6467e-07, 7.8616e-08, 9.6197e-09, 1.0343e-07,\n",
            "        3.9110e-07, 1.0916e-06, 9.9382e-08, 1.7470e-07, 3.8398e-09, 5.9278e-08,\n",
            "        9.6998e-08, 8.6508e-08, 4.9062e-08, 4.9245e-08, 1.4620e-07, 6.3801e-07,\n",
            "        2.8914e-09, 4.5457e-08, 1.2405e-07, 1.1396e-08, 4.7170e-07, 1.4233e-08,\n",
            "        1.4253e-07, 1.4634e-08, 1.4444e-08, 7.5652e-08, 3.8118e-08, 5.6882e-07,\n",
            "        4.6337e-08, 1.6734e-07, 3.9146e-08, 1.7795e-08, 1.3453e-07, 9.5255e-08,\n",
            "        5.6087e-08, 9.4642e-09, 3.0312e-08, 1.0784e-08, 1.7499e-07, 2.6946e-07,\n",
            "        3.0347e-08, 1.3070e-07, 1.8935e-09, 3.0374e-08, 5.5188e-07, 5.8801e-08,\n",
            "        1.0073e-07, 6.1531e-07, 2.5362e-07, 9.3579e-08, 2.4150e-06, 8.3308e-08,\n",
            "        3.3957e-08, 9.9476e-08, 2.5645e-07, 1.5564e-07, 4.4455e-09, 5.0178e-09,\n",
            "        1.2232e-07, 1.1894e-08, 1.0199e-07, 1.2519e-09, 9.0900e-08, 3.4053e-08,\n",
            "        1.3376e-08, 2.8791e-08, 4.2351e-08, 3.3084e-08, 6.8626e-08, 4.5738e-08,\n",
            "        3.5843e-07, 3.3618e-07, 2.0683e-08, 6.7966e-08, 1.5036e-06, 1.9381e-08,\n",
            "        1.8283e-09, 1.8996e-07, 5.7573e-09, 3.5337e-09, 2.8824e-07, 1.8660e-08,\n",
            "        5.3199e-08, 2.3497e-08, 3.5784e-08, 5.8454e-08, 4.1458e-08, 1.5949e-08,\n",
            "        3.0405e-07, 7.0147e-09, 5.4873e-07, 1.0535e-07, 6.8389e-08, 8.7034e-07,\n",
            "        2.6855e-07, 3.9091e-08, 7.4557e-07, 4.8079e-07, 4.1412e-09, 4.2621e-08,\n",
            "        4.5844e-10, 5.4241e-09, 6.4190e-07, 1.9688e-08, 7.9102e-09, 6.1521e-06,\n",
            "        7.9086e-09, 2.7185e-08, 3.0780e-09, 1.4822e-07, 1.0326e-08, 6.1604e-08,\n",
            "        1.1369e-07, 4.0285e-09, 3.6599e-07, 3.0215e-08, 2.4020e-07, 3.0380e-08,\n",
            "        2.1503e-08, 1.0775e-08, 2.1315e-07, 1.7528e-07, 3.9085e-07, 2.8787e-07,\n",
            "        1.6722e-07, 1.6655e-07, 2.5720e-07, 3.0090e-07, 3.4704e-08, 1.9312e-08,\n",
            "        1.6492e-05, 1.2655e-07, 1.2368e-07, 1.2811e-07, 1.5771e-07, 7.3541e-07,\n",
            "        2.0226e-08, 1.9236e-07, 1.4837e-08, 9.6464e-08, 5.9061e-08, 4.6575e-08,\n",
            "        6.2708e-07, 3.2251e-07, 1.1005e-07, 3.0724e-07, 3.4464e-07, 5.2785e-08,\n",
            "        1.0140e-07, 2.9551e-08, 8.0340e-09, 4.6271e-08, 4.7885e-08, 9.1142e-09,\n",
            "        5.3320e-09, 4.9678e-08, 3.3653e-07, 1.4787e-07, 2.2319e-07, 5.6224e-08,\n",
            "        2.9708e-07, 1.5427e-07, 1.0018e-07, 7.8505e-08, 1.5701e-08, 1.5119e-07,\n",
            "        2.8023e-07, 3.7859e-08, 8.2486e-08, 4.6472e-08, 1.8373e-08, 8.0612e-07,\n",
            "        3.3755e-08, 1.6264e-07, 5.4198e-10, 4.0916e-08, 4.7580e-08, 6.7007e-09,\n",
            "        2.4033e-07, 4.4512e-05, 1.8761e-07, 4.9963e-08, 1.9899e-08, 9.6009e-08,\n",
            "        3.2653e-07, 1.0596e-06, 2.0500e-08, 1.7776e-07, 5.2897e-08, 2.8140e-08,\n",
            "        2.0984e-08, 1.3256e-07, 7.7333e-08, 3.0895e-08, 3.7836e-08, 1.0865e-08,\n",
            "        3.8551e-08, 2.6524e-07, 2.8871e-07, 1.8188e-07, 4.7051e-08, 4.3812e-07,\n",
            "        1.2616e-07, 1.8826e-08, 3.1523e-08, 2.4157e-07, 2.7347e-08, 2.0062e-08,\n",
            "        5.2227e-08, 2.6586e-08, 1.3453e-07, 3.5947e-07, 4.8260e-07, 5.0215e-08,\n",
            "        6.1649e-08, 2.1713e-07, 4.8608e-07, 1.1949e-07, 1.8925e-07, 2.4013e-07,\n",
            "        1.8088e-08, 4.4492e-08, 1.7319e-08, 2.7715e-08, 2.5820e-07, 3.4678e-07,\n",
            "        1.1449e-05, 1.6560e-08, 4.4061e-08, 3.9369e-08, 1.1630e-08, 1.9996e-09,\n",
            "        2.6692e-08, 8.1262e-08, 7.0776e-09, 8.8692e-07, 6.6497e-08, 1.2542e-08,\n",
            "        3.5586e-08, 2.6881e-08, 1.9871e-08, 5.6323e-08, 3.3143e-08, 9.9331e-08,\n",
            "        3.7081e-07, 3.6696e-08, 5.6270e-08, 2.9870e-08, 6.6749e-09, 3.0097e-08,\n",
            "        8.7786e-06, 1.4130e-08, 1.8020e-07, 1.6556e-07, 3.9949e-07, 2.6017e-08,\n",
            "        2.9431e-07, 3.3215e-08, 1.0733e-08, 1.1853e-07, 7.7990e-09, 1.0511e-08,\n",
            "        2.0364e-08, 8.1640e-08, 4.0493e-08, 2.0787e-08, 3.4296e-08, 8.7276e-08,\n",
            "        4.4282e-08, 1.7785e-09, 9.9850e-07, 1.4496e-06, 2.3143e-07, 7.0443e-08,\n",
            "        2.6236e-08, 9.0222e-08, 3.3691e-07, 1.8932e-08, 2.7472e-07, 1.1870e-08,\n",
            "        8.0060e-09, 9.9683e-08, 9.7432e-09, 4.3988e-08, 1.8518e-07, 1.6843e-07,\n",
            "        3.0515e-07, 6.3705e-08, 4.1759e-08, 1.6937e-07, 6.6258e-08, 2.9977e-09,\n",
            "        6.1116e-08, 1.5883e-08, 7.6940e-09, 5.5658e-08, 8.9431e-10, 4.0575e-08,\n",
            "        5.9840e-09, 6.3923e-09, 2.7594e-09, 4.3483e-09, 4.0895e-09, 3.7822e-06,\n",
            "        8.3752e-09, 9.9926e-09, 4.5091e-08, 6.1663e-10, 5.1831e-09, 1.5318e-07,\n",
            "        5.4759e-08, 1.7677e-07, 2.5643e-07, 3.3771e-07, 1.1144e-08, 1.5758e-09,\n",
            "        4.9049e-08, 5.7115e-07, 8.2850e-09, 1.7346e-09, 2.9611e-09, 2.7437e-08,\n",
            "        5.0153e-07, 1.2224e-07, 5.6019e-09, 8.8352e-09, 4.5241e-09, 2.0733e-08,\n",
            "        2.7105e-08, 4.7836e-09, 1.5041e-08, 5.0161e-08, 6.2402e-08, 6.2928e-09,\n",
            "        1.8957e-08, 1.6209e-07, 5.4797e-09, 8.9128e-09, 4.3040e-10, 7.0131e-09,\n",
            "        4.8259e-08, 9.5581e-10, 5.9642e-08, 3.1602e-08, 1.2120e-07, 3.4439e-07,\n",
            "        2.4218e-08, 2.1158e-09, 6.6399e-08, 6.8796e-07, 1.4279e-08, 1.6187e-07,\n",
            "        2.5770e-08, 3.4816e-08, 4.0268e-08, 8.5079e-08, 2.3608e-07, 1.8331e-08,\n",
            "        3.2907e-08, 1.5054e-08, 8.1400e-09, 1.5156e-07, 2.3134e-09, 1.7163e-08,\n",
            "        2.0577e-08, 6.3081e-08, 4.4850e-08, 2.4505e-10, 1.2102e-08, 3.9299e-08,\n",
            "        1.2409e-08, 4.1150e-09, 1.3263e-07, 9.3352e-07], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
        "print(output[0])\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "print(probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "mature-transcription",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mature-transcription",
        "outputId": "53ad6e10-edd3-4405-adb5-5df166e11316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-02 18:55:19--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10472 (10K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt.5’\n",
            "\n",
            "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-02 18:55:19 (110 MB/s) - ‘imagenet_classes.txt.5’ saved [10472/10472]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download ImageNet labels\n",
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "qualified-alignment",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qualified-alignment",
        "outputId": "8367df75-2a15-4434-ea0d-fff133c70f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samoyed 0.8846218585968018\n",
            "Arctic fox 0.045805227011442184\n",
            "white wolf 0.044276293367147446\n",
            "Pomeranian 0.005621336400508881\n",
            "Great Pyrenees 0.004652000963687897\n"
          ]
        }
      ],
      "source": [
        "# Read the categories\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "# Show top categories per image\n",
        "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "for i in range(top5_prob.size(0)):\n",
        "    print(categories[top5_catid[i]], top5_prob[i].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "quantitative-metropolitan",
      "metadata": {
        "id": "quantitative-metropolitan"
      },
      "source": [
        "### Model Description\n",
        "\n",
        "Resnet models were proposed in \"Deep Residual Learning for Image Recognition\".\n",
        "Here we have the 5 versions of resnet models, which contains 18, 34, 50, 101, 152 layers respectively.\n",
        "Detailed model architectures can be found in Table 1.\n",
        "Their 1-crop error rates on imagenet dataset with pretrained models are listed below.\n",
        "\n",
        "| Model structure | Top-1 error | Top-5 error |\n",
        "| --------------- | ----------- | ----------- |\n",
        "|  resnet18       | 30.24       | 10.92       |\n",
        "|  resnet34       | 26.70       | 8.58        |\n",
        "|  resnet50       | 23.85       | 7.13        |\n",
        "|  resnet101      | 22.63       | 6.44        |\n",
        "|  resnet152      | 21.69       | 5.94        |\n",
        "\n",
        "### References\n",
        "\n",
        " - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}